---
# User customizable configuration to make a deployment in Nomad.
# Additional non-customizable values (eg. ports) are hardcoded in `job.nomad`.

# All conf parameters follow the same structure:
# varname:
#  name: name of the parameter to be displayed to end user (mandatory)
#  value: (default) value of the parameter (mandatory)
#  options: restricted set of values that the parameter can take (optional)
#  description: some comments on the parameter to be displayed to the end user (optional)

general:

  title:
    name: Deployment title
    value: ''
    description: Provide short title for this deployment (less than 45 characters). Useful when you have lots of different active deployments.

  desc:
    name: Deployment description
    value: ''
    description: Provide some additional extended information about this deployment.

  type:
    name: Deployment type
    value: 'both'
    description: Sub-components to deploy.
    options: ['both', 'vllm', 'open-webui']

vllm:

  gpu_memory_utilization:
    name: GPU memory utilization
    value:
    range: [0, 1]
    description: Fraction of GPU memory to be used.

  max_model_length:
    name: Maximum model length
    value:
    description: Maximum length of the model.

  tensor_parallel_size:
    name: Tensor parallel size
    value:
    description: Number of tensor parallel size.

  huggingface_token:
    name: Huggingface token
    value: ''
    description: Huggingface token to use.

  modelname:
    name: LLM name
    value: 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B'
    description: Large Language Model to use.
    options: ['deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', 'Qwen/Qwen2.5-1.5B-Instruct']
